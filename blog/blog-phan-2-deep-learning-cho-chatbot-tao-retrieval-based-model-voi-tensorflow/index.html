<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Phần 2: Deep Learning cho Chatbot - Tạo Retrieval-Based Model với Tensorflow | My real name is Tạ Minh Luận</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="TBD  Mở đầuĐây là bài dịch tiếp theo. Chúng ta sẽ cùng tạo một retrieval-based Model Chatbot. Nội dungTrong bài này chúng ta sẽ implement một retrieval-based bot. Retrieval-based model có một kho địn">
<meta property="og:type" content="article">
<meta property="og:title" content="Phần 2: Deep Learning cho Chatbot - Tạo Retrieval-Based Model với Tensorflow">
<meta property="og:url" content="https://taminhluan.github.io/blog/blog-phan-2-deep-learning-cho-chatbot-tao-retrieval-based-model-voi-tensorflow/index.html">
<meta property="og:site_name" content="My real name is Tạ Minh Luận">
<meta property="og:description" content="TBD  Mở đầuĐây là bài dịch tiếp theo. Chúng ta sẽ cùng tạo một retrieval-based Model Chatbot. Nội dungTrong bài này chúng ta sẽ implement một retrieval-based bot. Retrieval-based model có một kho địn">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://35.196.17.90/blog/wp-content/uploads/2018/12/ubuntu-dialog-corpus.png">
<meta property="og:image" content="http://35.196.17.90/blog/wp-content/uploads/2018/12/urc-test-validation-set.png">
<meta property="og:image" content="http://35.196.17.90/blog/wp-content/uploads/2018/12/dual-encoder-lstm.png">
<meta property="og:updated_time" content="2020-02-27T09:13:31.235Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Phần 2: Deep Learning cho Chatbot - Tạo Retrieval-Based Model với Tensorflow">
<meta name="twitter:description" content="TBD  Mở đầuĐây là bài dịch tiếp theo. Chúng ta sẽ cùng tạo một retrieval-based Model Chatbot. Nội dungTrong bài này chúng ta sẽ implement một retrieval-based bot. Retrieval-based model có một kho địn">
<meta name="twitter:image" content="http://35.196.17.90/blog/wp-content/uploads/2018/12/ubuntu-dialog-corpus.png">
  
    <link rel="alternate" href="/atom.xml" title="My real name is Tạ Minh Luận" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">My real name is Tạ Minh Luận</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://taminhluan.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-blog-phan-2-deep-learning-cho-chatbot-tao-retrieval-based-model-voi-tensorflow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/blog-phan-2-deep-learning-cho-chatbot-tao-retrieval-based-model-voi-tensorflow/" class="article-date">
  <time datetime="2018-12-02T02:19:39.000Z" itemprop="datePublished">2018-12-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Deep-learning/">Deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Phần 2: Deep Learning cho Chatbot - Tạo Retrieval-Based Model với Tensorflow
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>TBD</p>
</blockquote>
<h2 id="Mo-dau"><a href="#Mo-dau" class="headerlink" title="Mở đầu"></a>Mở đầu</h2><p>Đây là bài dịch tiếp theo. Chúng ta sẽ cùng tạo một retrieval-based Model Chatbot.</p>
<h2 id="Noi-dung"><a href="#Noi-dung" class="headerlink" title="Nội dung"></a>Nội dung</h2><p>Trong bài này chúng ta sẽ implement một retrieval-based bot. Retrieval-based model có một kho định nghĩa trước các câu trả lời chúng có thể sử dụng, không giống như generative models cái mà có thể generate câu trả lời chúng không bao giờ nhìn thấy trước đây. Rõ hơn, từ một câu đầu vào tới retrieval-based model là một context c sẽ chọn ra một câu trả lời response r có khả năng nhất. Ouputs của model là câu trả lời tốt nhất. Để tìm ra câu trả lời tốt nhất bạn cần phải tính toán điểm cho tất cả các câu trả lời và chọn ra một với số điểm cao nhất. Nhưng tại sao chúng ta lại tạo một retrieval-based model nếu chúng ta có thể tạo một generative model? Generative models dường như linh hoạt hơn bnowir vì chúng không cần kho câu trả lời định nghĩa trước, phải không các bạn? Vấn đề là generative models không hoạt động tốt trong thực tế. Ít nhất là cho tới bây giờ. Bởi vì chúng ta có quá nhiều tự do cho việc chúng có thể trả lời như thế nào, generative models có thể tạo ra các lỗi cú pháp, không có nghĩa, không nhất quán. Chúng cũng cần một số lượng dữ liệu training lớn và khó để tối ưu. Đa số hệ thống ngày nay là retrieval-based, hoặc kết hợp giữa retrieval-based và generative. Google’s Smart Reply là một ví dụ. Generative models đang là lĩnh vực active trong nghiên cứu. Nhưng chúng ta không quan trọng, nếu chúng ta tạo một chatbot ngày nay, lựa chọn tốt nhất là tạo một retrieval-based model</p>
<h3 id="The-Ubuntu-Dialog-Corpus"><a href="#The-Ubuntu-Dialog-Corpus" class="headerlink" title="The Ubuntu Dialog Corpus"></a>The Ubuntu Dialog Corpus</h3><p>Trong bài viết này chúng ta sẽ sử dụng Ubuntu Dialog Corpus (<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">paper</a>, <a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">github</a>). Ubuntu Dialog Corpus (UDC) là một trong những tập dữ liệu hội thoại lớn nhất được public. Nó được dựa trên các lưu trữ chat từ các kênh Ubuntu trên <strong>public</strong> <a href="https://vi.wikipedia.org/wiki/IRC" target="_blank" rel="noopener"><strong>IRC</strong></a> <strong>network</strong> (ok là một dạng liên lạc cấp tốc qua mạng gì đó).  <a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">Paper </a>này sẽ đi vào chi tiết chính xác dữ liệu được tạo như thế nào, vì thế tôi không lặp lại nó ở đây. Tuy nhiên, việc hiểu được dữ liệu là quan trọng khi chúng ta làm việc với chúng, vì thế để tôi giải thích nó trước. Tập dữ liệu training bao gồm 1000000 mẫu, với 50% positive (label 1), 50% negative (label 0). Mỗi vĩ dụ bao gồm <strong>context</strong>, là điểm bắt đầu hội thoại, và một <strong>utterance</strong>, một câu phản hồi cho context trên. Positive với label 1 nghĩa là câu phản hồi là thực sự cho context đó, và negative label 0 nghĩa là không phải, Chọn ngẫu nhiên một số mẫu, đây là một vài mẫu dữ liệu. <img src="http://35.196.17.90/blog/wp-content/uploads/2018/12/ubuntu-dialog-corpus.png" alt> Các dữ liệu được generation script đã được tiền xử lý cho chúng ta (cái này mình không biết là bản thân dữ liệu UDC được tiền xử lý hay là script của bài viết này tiền xử lý, mình sẽ xem thử và trình bày rõ cho các bạn) - Tiền xử lý ở đây là  <a href="http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize" target="_blank" rel="noopener">tokenized</a>, <a href="http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.snowball" target="_blank" rel="noopener">stemmed</a>, and <a href="http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.wordnet" target="_blank" rel="noopener">lemmatized</a> sử dụng <a href="http://www.nltk.org/" target="_blank" rel="noopener">NLTK tool</a>. Script này cũng đã thay thế các entities giống như tên, địa điểm, tổ chức, các url, các đường dẫn hệ thống bằng các ký tự đặc biệt. Việc tiền xử lý này không phải là phải làm, nhưng nó cũng sẽ giúp tăng hiệu quả một vài phần trăm. Trung bình context có 86 từ và utterance có 17 từ. Chúng ta có thể em chi tiết <a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/notebooks/Data%20Exploration.ipynb" target="_blank" rel="noopener">jupyter notebook.</a> Tập dữ liệu còn bao gồm cả tập test sets và validation sets (Ngắn gọn thì đây là 2 tập không để đem đi train mà là tập chưa nhìn thấy để đánh giá model). Định dạng của chúng khác với tập dữ liệu train. Mỗi dữ liệu trong test/validation bao gồm một context, một utterance đúng và 9 utterance sai được gọi là *<em>distractors. *</em>Mục đích của model là gán điểm cao nhất cho đúng utterance, và thấp hơn cho các utterances sai (ok). <img src="http://35.196.17.90/blog/wp-content/uploads/2018/12/urc-test-validation-set.png" alt> Có rất nhiều cách để đánh giá model. Cách thường sử dụng là recall@k. *<em>Recall@k *</em>nghĩa là model sẽ chọn ra k câu phản hồi tốt nhất trong 10 câu trả lời có thể (1 đúng và 10 sai). Nếu cái đúng nằm trong những cái mà chúng ta đã đánh dấu thì được coi là đúng (để dễ hiểu chọn k=3 ta chọn ra 3 câu phản hồi tốt nhất nếu trong 3 câu đó mà chứa câu đúng thì được coi là đúng). Vì thế k lớn hơn thì là dễ hơn. Nếu chúng ta set k=10 chúng ta sẽ có recall là 100% bởi vì chúng ta chỉ có 10 câu trả lời. Nếu chúng ta chọn k=1 thì model chỉ có một cơ hội để chọn ra câu trả lời đúng. Ở thời điểm này có lẽ bạn đang tự hỏi là 9 distractors(câu sai) được chọn như thế nào. Trong tập dữ liệu 9 câu sai được lấy ngẫu nhiên. Tuy nhiên trong thực tế bạn có cả triệu khả năng để chọn và bạn không biết được cái nào là đúng. Bạn không thể đánh giá cả triệu câu trả lời để lấy ra một cái có số điểm cao nhất - điều này là quá tốn kém (thời gian đôi khi hệ thống cần trả lời nhanh, ví dụ chatbot gửi câu yêu cầu là cần phản hồi nhanh không thể ngồi đợi đánh giá tất cả rồi chọn câu tốt nhất được, đến đây ta có thể mong ngóng bài viết sẽ đưa ra được mô hình tốt chứ không đơn giản như vậy). <a href="http://arxiv.org/abs/1606.04870" target="_blank" rel="noopener">Google Smart Reply </a>sử dụng kĩ thuật chia nhỏ các câu trả lời có thể chọn, hoặc nếu bạn chỉ có vài trăm câu trả lời thích hợp trong tất cả bạn có thể đánh giá tất. (Brute force được dùng ở mọi nơi phải không các bạn :D).</p>
<h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><p>Trước khi bắt đầu với mạng neural chúng ta hãy thử tạo ra một vài thứ đơn giản để giúp chúng ta có thể hiểu được hiệu quả chúng ta mong muốn. Chúng ta sẽ sử dụng function dưỡi đây để đánh giá recall@k: (Các mã code ở đây mình sẽ copy nguyên si để ta tôn trọng tác giả, mình sẽ implement một cái của riêng mình ở phía cuối cùng chúng ta sẽ cùng làm từ đầu).</p>
<p>def evaluate_recall(y, y_test, k=1):<br>    num_examples = float(len(y))<br>    num_correct = 0<br>    for predictions, label in zip(y, y_test):<br>        if label in predictions[:k]:
            num_correct += 1<br>    return num_correct/num_examples</p>
<p>Ở đây, y là tập các dự đoán của ta đã được sắp xếp theo điểm giảm dần, và y_test là các nhãn thực sự. Ví dụ y = [0,3,1,2,5,6,4,7,8,9] nghĩa là utteramce số 0 nhận điểm cao nhất, và 9 thấp nhất. Nhớ rằng chúng ta có 10 utterance, với mỗi test example và cái đầu tiên luôn là cái đúng, bởi vì trong dữ liệu test ở trên cột đúng đầu tiên, rồi đến 9 cái sai theo sau. Theo trực giác, nếu chọn một cách ngẫu nhiên ta có kết quả recall@1 là 10%, recall@2 là 20%, …Hãy xem trường hợp dưới đây.</p>
<p># Random Predictor<br>def predict_random(context, utterances):<br>    return np.random.choice(len(utterances), 10, replace=False)<br># Evaluate Random predictor<br>y_random = [predict_random(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]<br>y_test = np.zeros(len(y_random))<br>for n in [1, 2, 5, 10]:
    print(“Recall @ ({}, 10): {:g}”.format(n, evaluate_recall(y_random, y_test, n)))</p>
<p>Kết quả khi lấy ngẫu nhiên.</p>
<p><code>Recall @ (1, 10): 0.0937632</code></p>
<p><code>Recall @ (2, 10): 0.194503</code></p>
<p><code>Recall @ (5, 10): 0.49297</code></p>
<p><code>Recall @ (10, 10): 1</code></p>
<p>Great, trông có vẻ đã hoạt động. Đúng vậy nếu chúng ta chỉ lấy ngẫu nhiên. Một kiểu khác chúng ta sẽ thảo luận trong paper chính thức (hay research paper là các bài nghiên cứu) là tf-idf predictor. <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="noopener">tf-idf</a> là viết tắt của “term frequency inverse document”  tần số và các phép đo độ quan trọng của một từ trong một tài liệu quan hệ với cả corpus. Chúng ta không đi vào chi tiết (bạn có thể tìm thấy nhiều bài hướng dẫn về tf-idf trên mạng), các tài liệu có nội dung giống nhau sẽ có các một vector tf-idf tương tự (ok có thể sẽ có tutorial chống đạo văn từ cái này nhỉ). Rõ ràng nếu nội dung có các từ tương tự nhau chúng nhiều khả năng là cặp đúng. Ít nhất thì nó còn hơn là chọn ngẫu nhiên. Nhiều thư viện như scikit-learn có sẵn tf-idf functions, vì thế nên nó dễ dàng sử dụng. Chúng ta cùng tạo ra một tf-idf predictor và xem nó hoạt động tốt không.</p>
<p>class TFIDFPredictor:<br>    def __init__(self):<br>        self.vectorizer = TfidfVectorizer()</p>
<pre><code>def train(self, data):
    self.vectorizer.fit(np.append(data.Context.values,data.Utterance.values))

def predict(self, context, utterances):
    # Convert context and utterances into tfidf vector
    vector_context = self.vectorizer.transform(\[context\])
    vector_doc = self.vectorizer.transform(utterances)
    # The dot product measures the similarity of the resulting vectors
    result = np.dot(vector\_doc, vector\_context.T).todense()
    result = np.asarray(result).flatten()
    # Sort by top results and return the indices in descending order
    return np.argsort(result, axis=0)\[::-1\]</code></pre><p># Evaluate TFIDF predictor<br>pred = TFIDFPredictor()<br>pred.train(train_df)<br>y = [pred.predict(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]<br>for n in [1, 2, 5, 10]:
    print(“Recall @ ({}, 10): {:g}”.format(n, evaluate_recall(y, y_test, n)))</p>
<p>Kết quả</p>
<p><code>Recall @ (1, 10): 0.495032</code></p>
<p><code>Recall @ (2, 10): 0.596882</code></p>
<p><code>Recall @ (5, 10): 0.766121</code></p>
<p><code>Recall @ (10, 10): 1</code></p>
<p>Chúng ta có thể thấy rằng tf-idf model tốt hơn đáng kể so với chọn ngẫu nhiên. Nhưng nó chưa được hoàn hảo. Giả định rằng chúng ta đã làm không được tốt. Đầu tiên một câu trả lời không cần thiết phải giống với câu context.</p>
<p>Thứ hai, tf-idf bỏ qua thứ tự của từ, cái có thể là một tín hiệu quan trọng. Với một Neural Network model chúng ta có thể làm tốt hơn.</p>
<h3 id="Dual-Encoder-LSTM"><a href="#Dual-Encoder-LSTM" class="headerlink" title="Dual Encoder LSTM"></a>Dual Encoder LSTM</h3><p>Deep learning model mà chúng ta sẽ tạo ra trong bài viết này được gọi là Dual Encoder LSTM network. Đây chỉ là một trong nhiều cách chúng ta có thể áp dụng cho vấn đề này và nó không phải là cái tốt nhất. Bạn có thể thử với các loại kiến trúc Deep learning khác cái chưa được thử - nó là một lĩnh vực đang được nghiên cứu. Lấy ví dụ,  <a href="https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html" target="_blank" rel="noopener">seq2seq model</a> thường xuyên được sử dụng trong Machine Translation (ở bài sau mình sẽ trình bày mô hình này cũng như chatbot mình làm được, mình cứ nghĩ cái mình làm được là generative model, nhưng có vẻ nó chỉ là retieval model thôi. Các bạn có thể trả lời câu hỏi này giúp mình nhé. Cám ơn các bạn) cái mà sẽ hoạt động tốt cho nhiệm vụ này. Lý do chúng ta chọn Dual Encoder là bởi vì nó <a href="http://arxiv.org/abs/1510.03753" target="_blank" rel="noopener">được báo cáo</a> đạt được hiệu quả tốt trên tập dữ liệu này. Điều này có nghĩa là chúng ta biết là cái chúng ta mong đợi có thể chắc chắn model của chúng ta sẽ hoạt động tốt. Việc áp dụng các model khác cho vấn đề này sẽ là một dự án thú vị. The Dual Encoder LSTM chúng ta sẽ tạo giống như (<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">paper</a>): <img src="http://35.196.17.90/blog/wp-content/uploads/2018/12/dual-encoder-lstm.png" alt> Nó hoạt đống giống như sau:</p>
<ol>
<li>Tất cả các context và response được chia thành các từ và được chuyển thành dạng vector với embedded (đơn giản nó là một vector được xây dựng sẵn ví dụ từ “father” = [0 2.1 -3.4 …. 2.5] mình ví dụ như vậy). Word Embeddings được khởi tạo từ Stanford’s <a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">GloVe</a> vectors và được fine-tuned trong suốt quá trình training (Side note: Điều này là không bắt buộc và không được thể hiện trong bức tranh. Tôi tìm thấy các word embeddings với GloVe không làm tạo ra sự khác biệt cho độ hiệu quả của model). (ok vậy cũng không quan trọng lắm việc chất lượng word embedded và việc fine-turned được nói ở trên liệu có phải trong quá trình train mình sẽ sửa lại cái ma trận word embbeded được cung cấp sẵn không, model của mình làm thì mình không thay đổi ma trận này).</li>
<li>Tất cả các embedded context và response được cho vào cùng một Recurrent Neural Network word-by-word. Chúng ta có thể chọn vectors lớn hơn, ở đây chúng ta chọn 256 chiều.(ok mình hiểu một từ được biểu diễn 256 con số ví dụ từ “father” bên trên sẽ chuyển thành ma trận 256 cột).</li>
<li>Chúng ta sẽ nhân c với một ma trận M để dự đoán kết quả r’. Nếu c là 1x256 chiều, thì M là 256x256 và kết quả sẽ được là vector 1x256, cái chúng ta có thể tạo ra như là generated response. Ma trận M này sẽ được học trong suốt quá trình train.(ok ma trận này được khởi tạo ngẫu nhiên và trong quá trình train ma trận này sẽ thay đổi trọng số để có thể từ đầu vào sẽ tạo ra đúng đầu ra).</li>
<li>Chúng ta sẽ đo sự giống nhau của kết quả r’ và kết quả thực sự bằng cách dot product(nhân ma trận) giữa hai vector. Một dot product lớn nghĩa là hai vectors giống nhau.(ok 1x256 nhân 256x1 sẽ được 1x1 một số nhưng mình vẫn chưa hiểu sao số này lớn 2 vector lại giống nhau ví dụ 0.1x0.5 &gt; 0.1x0.1 nhưng 0.1 và 0.1 giống nhau hơn). Sau đó chúng ta sẽ áp dụng hàm sigmoid function để chuyển kết quả này thành xác suất. Bước 3 và 4 đã bao gồm trong hình.</li>
</ol>
<p>Để train model, chúng ta cần một loss(cost) function. Chúng ta sẽ sử dụng binary cross-entropy loss là thường sử dụng cho classification problems. Chúng ta sẽ gọi true label cho cặp context-response y. 1 đúng 0 sai. Lấy predicted xác suất từ 4. Sau đó dùng cross entropy loss được tính toán L= −y * ln(y’) − (1 − y) * ln(1−y’). (ok các bạn không cần quá lo lắng chúng ta có sẵn cross entropy loss trong các deep learning framework như tensorflow, pytorch, … Nếu các bạn vẫn cảm thấy khó chịu thì chúng ta sẽ học machine learning căn bản và deep learning, thời gian sẽ trả lời, …). Chúng ta sẽ sử dụng cả numpy, pandas, tensorflow và tf learn(tổng hợp của các hàm tiện ích bậc cao cho tensorflow cái này mình không biết mình dùng tensorflow low level và thấy thuận tiện còn muốn high level thì mình dùng keras món tf learn này mình chưa thử).</p>
<h3 id="Tien-xu-ly"><a href="#Tien-xu-ly" class="headerlink" title="Tiền xử lý"></a>Tiền xử lý</h3><p><a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">Dataset</a> chính thức có định dạng CSV. Chúng ta có thể làm việc trực tiếp với CSV nhưng tốt hơn để thuận tiện cho việc chuyển dữ liệu sang dạng tensorflow. (Quick side note: tf.SequenceExample nhưng nó dường như không được hỗ trợ bởi tf.learn nữa. ok bản thân mình không hiểu mấy cái này). Lợi ích chính của định dạng này là cho phép chúng ta load tensor trực tiếp từ input files và để tensorflow xử lý tất cả việc shuffling, batching, queuing của inputs (ok nghe hay nhỉ). Một phần của việc tiền xử lý là chúng ta cần tạo ra vocabulary. Nghĩa là chúng ta sẽ map mỗi từ thành một con số, ví dụ “cat” thành 2631. TFRecord files sẽ chuyển lưu trữ thành các con số thay thế các chuỗi. Chúng ta sẽ lưu vocabulary vì thế chúng ta có thể map các con số trở lại thành các từ sau này. Mỗi một example sẽ bao gồm các trường sau: context: Một sequence of word ids được biểu diễn context text ví dụ [231, 2190, 737, 0, 912] biểu diễn cho “tf learn làm hết rồi”. context_len: Chiều dài của context là 5 cho ví dụ bên trên utterance: Một sequence of word ids biểu diễn cho utterance (response) utterance_len: Chiều dài utterance label: Chỉ cho training data là 0 hoặc 1 distractor_[N]: Chỉ cho test/validation data. N từ 0 đến 9. Một sequence of word ids trình bày distractor utterance distractor_[N]_len: Chỉ cho test/validation data, chiều dài cho cái bên trên The preprocessing đã xong với  <a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/scripts/prepare_data.py" target="_blank" rel="noopener"><code>prepare_data.py.</code></a>Python script, cái sẽ tạo ra 3 files: <code>train.tfrecords</code>, <code>validation.tfrecords</code> and <code>test.tfrecords</code>. Bạn có thể tự chạy script hoặc tải các data file từ <a href="https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM" target="_blank" rel="noopener">đây </a>.</p>
<h3 id="Tao-mot-input-function"><a href="#Tao-mot-input-function" class="headerlink" title="Tạo một input function"></a>Tạo một input function</h3><p>Để sử dụng Tensorflow’s built-in hỗ trợ cho việc training và đánh giá chúng ta cần tạo ra các input function - một function sẽ trả về tập dữ liệu cho chúng ta. Trong thực tế, bởi vì dữ liệu training và dữ liệu test khác nhau về định dạng, chúng ta cần phải có các input functions khác nhau cho chúng. Input function nên trả về batch of features và nhãn (nếu có sẵn). Đây là một vài dòng mã giả:</p>
<p>def input_fn():</p>
<h1 id="TODO-Load-and-preprocess-data-here"><a href="#TODO-Load-and-preprocess-data-here" class="headerlink" title="TODO Load and preprocess data here"></a>TODO Load and preprocess data here</h1><p>  return batched_features, labels</p>
<p>Bởi vì chúng ta cần input function khác nhau trong suốt quá trình training và đánh giá và bởi vì chúng ta ghét việc phải lặp lại code, chúng ta tạo ra một wrapper gọi là create_input_fn cái mà tạo ra một input function cho các mode thích hợp. Nó thêm một vài tham số khác. Đây là định nghĩa chúng ta sử dụng:</p>
<p>def create_input_fn(mode, input_files, batch_size, num_epochs=None):<br>  def input_fn():</p>
<pre><code># TODO Load and preprocess data here
return batched_features, labels</code></pre><p>  return input_fn</p>
<p>Đầy đủ code chúng ta có thể tìm thấy trong <code>[udc_inputs.py](https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_inputs.py).</code>Một high level function làm được những thứ sau:</p>
<ol>
<li>Tạo một feature definition để mô tả các trường của chúng ta.</li>
<li>Đọc vào các dòng từ input_files với tf.TFRecordReader</li>
<li>Parse các records thành các feature definition (có lẽ là thành một example với định dạng như phần tiền xử lý mình nói ở trên)</li>
<li>Trích xuất training labels</li>
<li>Tạo batch nhiều mẫu và training labels</li>
<li>Trả về batch và training labels</li>
</ol>
<p>Định nghĩa cách đánh giá model. Chúng ta đã nhắc đến việc chúng ta muốn sử dụng recall@k metric để đánh giá model của chúng ta. Thật may mắn Tensorflow đã có sẵn với nhiều evaluation metrics cho chúng ta có thể sử dụng bao gồm cả including recall@k. Để sử dụng metrics này chúng ta cần tạo một từ điển maps từ tên số liệu tới một hàm nhận predictions (cái chúng ta dự đoán) và labels(kết quả thật sự) làm tham số.</p>
<p>def create_evaluation_metrics():<br>  eval_metrics = {}<br>  for k in [1, 2, 5, 10]:
    eval_metrics[“recall_at_%d” % k] = functools.partial(<br>        tf.contrib.metrics.streaming_sparse_recall_at_k,<br>        k=k)<br>  return eval_metrics</p>
<p>Bên trên chúng ta sử dụng  <code>[functools.partial](https://docs.python.org/2/library/functools.html#functools.partial)</code> để chuyển functions nhận 3 tham số tới một cái functions nhận hai tham số (mình không thực sự hiểu lắm). Đừng để tên streaming_sparse_recall_at_k khiến bạn nhầm lẫn. Streaming chỉ có nghĩa là hàm tích lũy thông qua các batches và làm rời rạc để cùng định dạng với labels của chúng ta (kiểu cộng dồn qua các batch và chuyển về dạng 0 1 với định dạng labels). Điều này mang lại một điểm quan trọng: Định dạng chính xác cho predictions là gì? Trong suốt quá trình training chúng ta dự đoán xác suất của các example là đúng. Nhưng trong suốt quá trình đánh giá mục đích của chúng ta là tính điểm cho utterance và 9 distractors và chọn ra cái tốt nhất. Bài viết chưa hoàn thành, mình sẽ cập nhật sớm nhất có thể, …</p>
<h3 id="Ket-luan"><a href="#Ket-luan" class="headerlink" title="Kết luận"></a>Kết luận</h3><p>Trong bài viết này chúng ta đã implemented một retrieval-based neural network model cái có thể assign score tới câu trả lời tiềm năng với một context cho trước. Vẫn có nhiều điểm để cải thiện như thử các neural networks khác làm tốt hơn nhiệm vụ này hơn là Dual LSTM encoder. Cũng có nhiều hyperparameter optimization hoặc cải thiện quá trình tiền xử lý. <strong><a href="https://github.com/dennybritz/chatbot-retrieval/" target="_blank" rel="noopener">The Code and data for this tutorial is on Github, so check it out.</a></strong></p>
<h2 id="Ket-thuc"><a href="#Ket-thuc" class="headerlink" title="Kết thúc"></a>Kết thúc</h2><p>Như vậy là mình đã dịch xong <a href="http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/" target="_blank" rel="noopener">http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/</a> Đây là một bài hướng dẫn hay phải không các bạn. Còn một số chỗ mình chưa hiểu, và mình cũng chưa tự làm lại thì chưa thể nói là của mình được. Tóm lại chúng ta sử dụng recall@k để đánh giá, sử dụng Dual LSTM encoder để train, if-idf để biết được độ giống nhau với tham vọng làm được một hệ thống chống đạo văn, Ngoài keras còn có một thứ tên là tf-learn nữa cần phải đọc qua, và cái chatbot mình đang build dùng seq2seq machine translation model thì có vẻ là một dạng retrieval based model chứ không phải generative models. Mình mong bài hướng dẫn cho các bạn và có thể góp ý các phần bình luận trong đóng mở ngoặc tròn mà mình còn chưa hiểu. Trong bài tiếp theo mình sẽ hướng dẫn tiếp tạo chatbot với mô hình seq2seq. Cám ơn các bạn</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://taminhluan.github.io/blog/blog-phan-2-deep-learning-cho-chatbot-tao-retrieval-based-model-voi-tensorflow/" data-id="ck74jjgv700du2mcp1oov7454" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/blog/blog-phan-3-deep-learning-cho-chatbot-tao-mot-generative-chatbot/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Phần 3: Deep Learning cho Chatbot - Thiết kế generative Chatbot
        
      </div>
    </a>
  
  
    <a href="/blog/blog-phan-1-deep-learning-cho-chatbot-gioi-thieu/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Phần 1: Deep learning cho Chatbot - Giới thiệu</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android-Programming/">Android Programming</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Android-Programming/Note/">Note</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Assembly/">Assembly</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Book/">Book</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Code-Viblo/">Code Viblo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Codesignal/">Codesignal</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-learning/">Deep learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GIS/">GIS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linh-tinh/">Linh tinh</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Lap-trinh/">Lập trình</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-learning/">Machine learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network-Programming/">Network Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Note/">Note</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/OWASP-Testing-Guide/">OWASP Testing Guide</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Phim/">Phim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pre-Calculus/">Pre Calculus</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Social-engineering/">Social engineering</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/System-Programming/">System Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Text-to-speech/">Text to speech</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Text-to-speech/Tool/">Tool</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Toan-hoc/">Toán học</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tri-tue-nhan-tao/">Trí tuệ nhân tạo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Uncategorized/">Uncategorized</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Unit-Testing/">Unit Testing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Visualisation/">Visualisation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ctf/">ctf</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hacker/">hacker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/note/">note</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tools/">tools</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/vnspoj/">vnspoj</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/wordpress/">wordpress</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Do-an/">Đồ án</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ASP-net-MVC/">ASP.net MVC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android-Programming/">Android Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Angular/">Angular</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Asp-net/">Asp.net</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Assembly/">Assembly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Basic-Access-Authentication/">Basic Access Authentication</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Blog/">Blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Book/">Book</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C#</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code/">Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Course/">Course</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Digest-Access-Authentication/">Digest Access Authentication</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django/">Django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Du-doan-gia-vang/">Dự đoán giá vàng</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ethical-Hacking/">Ethical Hacking</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flask/">Flask</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GIS/">GIS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Html-css-javascript/">Html, css, javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Laravel/">Laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux-System-Programming/">Linux, System Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OWASP-Testing-Guide/">OWASP Testing Guide</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Php/">Php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python-Codesignal/">Python, Codesignal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Quan-ly-diem/">Quản lý điểm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RFC-2069/">RFC 2069</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RFC-2617/">RFC 2617</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SJF/">SJF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Social-engineering/">Social engineering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spring-MVC/">Spring MVC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sql-server/">Sql server</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System-Programming/">System Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Text-to-speech/">Text to speech</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Todos/">Todos</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tinh-toan-mem/">Tính toán mềm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VRML/">VRML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WPF/">WPF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows/">Windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows-Form/">Windows Form</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Winform/">Winform</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Winforms/">Winforms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Wordpress/">Wordpress</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf/">ctf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/database/">database</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fuzzy-computing/">fuzzy computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/import-csv/">import csv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/migrate/">migrate</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wordpress/">wordpress</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ASP-net-MVC/" style="font-size: 10px;">ASP.net MVC</a> <a href="/tags/Android/" style="font-size: 10px;">Android</a> <a href="/tags/Android-Programming/" style="font-size: 10px;">Android Programming</a> <a href="/tags/Angular/" style="font-size: 10px;">Angular</a> <a href="/tags/Asp-net/" style="font-size: 10px;">Asp.net</a> <a href="/tags/Assembly/" style="font-size: 14px;">Assembly</a> <a href="/tags/Basic-Access-Authentication/" style="font-size: 10px;">Basic Access Authentication</a> <a href="/tags/Blog/" style="font-size: 10px;">Blog</a> <a href="/tags/Book/" style="font-size: 10px;">Book</a> <a href="/tags/C/" style="font-size: 20px;">C#</a> <a href="/tags/Code/" style="font-size: 14px;">Code</a> <a href="/tags/Course/" style="font-size: 10px;">Course</a> <a href="/tags/Digest-Access-Authentication/" style="font-size: 10px;">Digest Access Authentication</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Du-doan-gia-vang/" style="font-size: 10px;">Dự đoán giá vàng</a> <a href="/tags/Ethical-Hacking/" style="font-size: 10px;">Ethical Hacking</a> <a href="/tags/Flask/" style="font-size: 10px;">Flask</a> <a href="/tags/GIS/" style="font-size: 10px;">GIS</a> <a href="/tags/Html-css-javascript/" style="font-size: 10px;">Html, css, javascript</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Laravel/" style="font-size: 10px;">Laravel</a> <a href="/tags/Linux/" style="font-size: 20px;">Linux</a> <a href="/tags/Linux-System-Programming/" style="font-size: 10px;">Linux, System Programming</a> <a href="/tags/Note/" style="font-size: 16px;">Note</a> <a href="/tags/OWASP-Testing-Guide/" style="font-size: 12px;">OWASP Testing Guide</a> <a href="/tags/Php/" style="font-size: 16px;">Php</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Python-Codesignal/" style="font-size: 10px;">Python, Codesignal</a> <a href="/tags/Quan-ly-diem/" style="font-size: 10px;">Quản lý điểm</a> <a href="/tags/RFC-2069/" style="font-size: 10px;">RFC 2069</a> <a href="/tags/RFC-2617/" style="font-size: 10px;">RFC 2617</a> <a href="/tags/SJF/" style="font-size: 10px;">SJF</a> <a href="/tags/Social-engineering/" style="font-size: 14px;">Social engineering</a> <a href="/tags/Spring-MVC/" style="font-size: 10px;">Spring MVC</a> <a href="/tags/Sql-server/" style="font-size: 10px;">Sql server</a> <a href="/tags/System-Programming/" style="font-size: 14px;">System Programming</a> <a href="/tags/Text-to-speech/" style="font-size: 10px;">Text to speech</a> <a href="/tags/Todos/" style="font-size: 10px;">Todos</a> <a href="/tags/Tool/" style="font-size: 10px;">Tool</a> <a href="/tags/Tinh-toan-mem/" style="font-size: 10px;">Tính toán mềm</a> <a href="/tags/VRML/" style="font-size: 12px;">VRML</a> <a href="/tags/WPF/" style="font-size: 10px;">WPF</a> <a href="/tags/Windows/" style="font-size: 10px;">Windows</a> <a href="/tags/Windows-Form/" style="font-size: 10px;">Windows Form</a> <a href="/tags/Winform/" style="font-size: 10px;">Winform</a> <a href="/tags/Winforms/" style="font-size: 14px;">Winforms</a> <a href="/tags/Wordpress/" style="font-size: 18px;">Wordpress</a> <a href="/tags/ctf/" style="font-size: 10px;">ctf</a> <a href="/tags/database/" style="font-size: 10px;">database</a> <a href="/tags/fuzzy-computing/" style="font-size: 10px;">fuzzy computing</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/import-csv/" style="font-size: 10px;">import csv</a> <a href="/tags/migrate/" style="font-size: 10px;">migrate</a> <a href="/tags/php/" style="font-size: 10px;">php</a> <a href="/tags/wordpress/" style="font-size: 10px;">wordpress</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/blog-2020-02-27-Lam-sao-de-tra-luong-lap-trinh-vien-it-hon/">Làm sao để trả lương lập trình viên ít hơn</a>
          </li>
        
          <li>
            <a href="/blog/blog-hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/blog/blog-2020-02-17-The-art-of-computer-prgramming-PREFACE/">The art of computer prgramming PREFACE</a>
          </li>
        
          <li>
            <a href="/blog/blog-2020-02-11-Geographical-Information-Systems-Part-1-Coursera-Week-1/">Geographical Information Systems Part 1 Coursera - Week 1</a>
          </li>
        
          <li>
            <a href="/blog/blog-2020-01-09-OWASP-Testing-Guide-2-Conduct-search-engine-discorvery-reconnaissance-for-information-leakage-OTG-INFO-001/">OWASP Testing Guide - 2 Conduct search engine discorvery/reconnaissance for information leakage (OTG-INFO-001) </a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 LuanTM<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>